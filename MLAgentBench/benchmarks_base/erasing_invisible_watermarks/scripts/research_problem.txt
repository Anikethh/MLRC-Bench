Research Problem: Invisible Watermark Removal

Task Description:
This task is based on the NeurIPS 2024 Competition "Erasing the Invisible: A Stress-Test Challenge for Image Watermarks". Your goal is to develop methods to remove invisible watermarks from images while maintaining image quality.

The task implements the Beige-box attack track with the Stable Signature watermarking method. The beige-box attack track provides participants with watermarked images along with information about the watermarking methodology used. This transparent approach with known watermarking methods enables the development of specialized attack strategies tailored to each specific watermarking technique, fostering a deeper understanding of watermark vulnerabilities and robustness characteristics.

Specifically, this track focuses on the Stable Signature watermarking algorithm, which is developed for latent diffusion models—such as those used in modern generative image systems—that embeds an invisible, robust watermark directly into the model's latent decoder. In essence, the method fine-tunes the decoder so that every image generated by the model carries a hidden binary signature. This signature is imperceptible to the human eye yet can be later extracted using a pre-trained watermark detector which applies a statistical test to verify the image's origin. 

In the beige-box setting, the primary challenge is optimal attack strategy development. With knowledge of the watermarking methodology, participants must design attacks that exploit known characteristics of specific watermarking techniques while maintaining image quality. This requires deep understanding of various watermarking algorithms and their potential vulnerabilities. The challenge lies in developing attacks that can effectively leverage this knowledge while still operating within practical computational constraints.

Dataset Structure: you will find 1k watermarked and unwatermakred images for development under `data/dev/watermarked` and `data/dev/unwatermarked`.

Implementation Steps:
1. Review methods/MyMethod.py for the baseline implementation and understanding the approach based on frequency domain filtering. The algorithm removes a watermark by converting the image into its frequency domain using FFT, then applying a radial mask that suppresses frequencies likely containing the watermark, and finally converting back to the spatial domain via inverse FFT. It simultaneously applies Gaussian smoothing to the original image and blends the two results before adjusting the color statistics to match the original, thereby effectively reducing watermark traces while preserving image quality.

2. Complete the template in BaseMethod.py by implementing:
   ```python
   def _build_model(self):
       # Define your model architecture
       pass

   def remove_watermark(self, image):
       # Implement watermark removal logic
       pass
   ```
3. Save your implementation as a new file under `methods/` that extends BaseMethod

4. Add the new method to the dictionary returned by `all_method_handlers()` in `methods/__init__.py`.

5. Add the new module to `methods/__init__.py`.

6. Test your implementation: Simply run `python main.py -m {method_name}`. For example, to test the baseline method, execute `python main.py -m my_method`.

Evaluation Framework:
The competition employs a sophisticated evaluation metric that combines image quality and watermark removal effectiveness. The scoring formula sqrt(Q² + A²) represents this dual objective, where:

Image quality metrics include 8 metrics in 4 categories: (1) Image similarities, including Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), and Normalized Mutual Information (NMI), which assess the pixel-wise accuracy after attacks; (2) Distribution distances such as Frechet Inception Distance (FID) and a variant based on CLIP feature space (CLIPFID); (3) Perception-based metrics like Learned Perceptual Image Patch Similarity (LPIPS); (4)Image quality assessments including aesthetics and artifacts scores, which quantify the changes in aesthetic and artifact features.

Quality Degredation Score (Q) synthesizes multiple image quality metrics through a carefully calibrated weighting scheme:
Q = +1.53×10⁻³ FID + 5.07×10⁻³ CLIP FID - 2.22×10⁻³ PSNR - 1.13×10⁻¹ SSIM - 9.88×10⁻² NMI + 3.41×10⁻¹ LPIPS + 4.50×10⁻² ΔAesthetics - 1.44×10⁻¹ ΔArtifacts

The Accuracy Score (A) measures watermark removal effectiveness through TPR@0.1%FPR, evaluated against a comprehensive corpus of unwatermarked images. In the beige-box context, this metric evaluates how effectively solutions can exploit known watermark characteristics while maintaining image quality.

Lower scores indicate better performance in both watermark removal and quality preservation.
