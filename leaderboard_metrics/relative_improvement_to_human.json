{
  "perception_temporal_action_loc": {
    "MLAB (claude-3-5-sonnet-v2)": 0.8,
    "Top Human in Competition": 100.0,
    "MLAB (gemini-exp-1206)": -0.5,
    "MLAB (o3-mini)": 0.3,
    "MLAB (gpt-4o)": 0.3,
    "MLAB (llama3-1-405b-instruct)": 0.5,
    "CoI-Agent (o1) + MLAB (gpt-4o)": 0.4
  },
  "llm-merging": {
    "CoI-Agent (o1) + MLAB (gpt-4o)": -1.0,
    "Top Human in Competition": 100.0,
    "MLAB (claude-3-5-sonnet-v2)": 5.0,
    "MLAB (gemini-exp-1206)": 5.0,
    "MLAB (o3-mini)": -1.0,
    "MLAB (gpt-4o)": 2.0,
    "MLAB (llama3-1-405b-instruct)": -1.0
  },
  "meta-learning": {
    "CoI-Agent (o1) + MLAB (gpt-4o)": 1.8,
    "Top Human in Competition": 100.0,
    "MLAB (claude-3-5-sonnet-v2)": 1.8,
    "MLAB (gemini-exp-1206)": 1.8,
    "MLAB (o3-mini)": -4.9,
    "MLAB (gpt-4o)": 1.8,
    "MLAB (llama3-1-405b-instruct)": 1.8
  },
  "product-recommendation": {
    "CoI-Agent (o1) + MLAB (gpt-4o)": 0.6,
    "Top Human in Competition": 100.0,
    "MLAB (claude-3-5-sonnet-v2)": 3.0,
    "MLAB (gemini-exp-1206)": 0.1,
    "MLAB (o3-mini)": 0.1,
    "MLAB (gpt-4o)": 0.6,
    "MLAB (llama3-1-405b-instruct)": -0.0
  },
  "weather_forcast": {
    "CoI-Agent (o1) + MLAB (gpt-4o)": 20.9,
    "Top Human in Competition": 100.0,
    "MLAB (claude-3-5-sonnet-v2)": 7.8,
    "MLAB (gemini-exp-1206)": 22.9,
    "MLAB (o3-mini)": 13.3,
    "MLAB (gpt-4o)": 25.2,
    "MLAB (llama3-1-405b-instruct)": 16.7
  },
  "machine_unlearning": {
    "CoI-Agent (o1) + MLAB (gpt-4o)": 14.2,
    "Top Human in Competition": 100.0,
    "MLAB (claude-3-5-sonnet-v2)": -94.7,
    "MLAB (gemini-exp-1206)": 5.6,
    "MLAB (o3-mini)": 3.6,
    "MLAB (gpt-4o)": -18.0,
    "MLAB (llama3-1-405b-instruct)": 6.2
  },
  "erasing_invisible_watermarks": {
    "CoI-Agent (o1) + MLAB (gpt-4o)": 84.0,
    "Top Human in Competition": 100.0,
    "MLAB (claude-3-5-sonnet-v2)": 87.6,
    "MLAB (gemini-exp-1206)": 97.5,
    "MLAB (o3-mini)": 83.4,
    "MLAB (gpt-4o)": 83.4,
    "MLAB (llama3-1-405b-instruct)": 83.4
  },
  "backdoor-trigger-recovery": {
    "CoI-Agent (o1) + MLAB (gpt-4o)": 13.7,
    "Top Human in Competition": 100.0,
    "MLAB (claude-3-5-sonnet-v2)": 39.9,
    "MLAB (gemini-exp-1206)": 12.9,
    "MLAB (o3-mini)": 6.2,
    "MLAB (gpt-4o)": 10.4,
    "MLAB (llama3-1-405b-instruct)": 11.5
  }
}
